# SSV360
A Dataset for Standing and Seated Viewing of 360° Videos on Subjective Quality Assessment

## Abstract
In this paper, we introduce the SSV360 dataset containing psychophysical and psychophysiological data gathered in a pilot study on the effect of standing and seated viewing of 360 videos on subjective quality assessment. The stimuli were shown to the participants on a head-mounted display for both viewing conditions. The ground truth contained in the SSV360 dataset may support, e.g., benchmarking of immersive media processing algorithms and developing objective perceptual quality metrics.



## Citation
To use the SSV360 dataset in published work, please cite the following papers:
- SSV360 dataset
```
text
```

- MDPI Journal article
```
@article{YAN21,
author  = {Y. Hu and M. Elwardy and Hans-J\"urgen Zepernick},
title   = {{On the Effect of Standing and Seated Viewing of 360$^{\circ}$ Videos on Subjective Quality Assessment: A Pilot Study}},
journal = {Computers},
volume  = {10},
number  = {6},
pages   = {80},
month   = {Jun.},
year    = {2021}
}
```

## Acknowledgements


## Contact
If you have any question about our SSV360 dataset, please use the [public issues section](https://github.com/MajedElwardy/SSV360/issues) on this Github repo. 

Alternatively, contact the authors:
- Majed Elwardy : majed.elwardy@bth.se (main author)
- Hans-Jürgen Zepernick: hans-jurgen.zepernick@bth.se
- Yan Hu: yan.hu@bth.se

Please send email in the format as follow:

> * subject: SSV360


